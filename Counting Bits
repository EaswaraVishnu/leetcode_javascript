Given an integer n, return an array ans of length n + 1 such that for each i (0 <= i <= n), ans[i] is the number of 1's in the binary representation of i.

Example 1:

Input: n = 2
Output: [0,1,1]
Explanation:
0 --> 0
1 --> 1
2 --> 10
Example 2:

Input: n = 5
Output: [0,1,1,2,1,2]
Explanation:
0 --> 0
1 --> 1
2 --> 10
3 --> 11
4 --> 100
5 --> 101

Solution:

var countbits = function(n){
    let start = []
    for (let i = 0;i <=n;i++){
        const binary = i.toString(2);
        start.push(binary)
    }
    let mid = []
    let final = []
    for (let j=0;j < start.length;j++)
    {
        let sum = 0
        mid = (start[j].split(""))
        for (a = 0;a<mid.length;a++){
            sum +=Number(mid[a])
        }
        final.push(sum)
    }
    return (final);
}
countbits(2)
